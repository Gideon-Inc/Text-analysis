# coding=utf-8
import pandas
import numpy as np
from sklearn import datasets
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import KFold

import sys
sys.path.append("..")
from shad_util import print_answer


'''1. Загрузите объекты из новостного датасета 20 newsgroups, относящиеся к категориям "космос"и "атеизм"(инструкция приведена выше).
2. Вычислите TF-IDF-признаки для всех текстов. Обратите внимание, что в этом задании мы предлагаем вам вычислить TF-IDF по
всем данным. При таком подходе получается, что признаки на обучающем множестве используют информацию из тестовой выборки
— но такая ситуация вполне законна, поскольку мы не используем значения целевой переменной из теста. На практике нередко
встречаются ситуации, когда признаки объектов тестовой выборки
известны на момент обучения, и поэтому можно ими пользоваться
при обучении алгоритма.
3. Подберите минимальный лучший параметр C из множества [10−5
, 10−4
, ...104
, 105
]
для SVM с линейным ядром (kernel=’linear’) при помощи кросс3
валидации по 5 блокам. Укажите параметр random_state=241 и
для SVM, и для KFold. В качестве меры качества используйте долю верных ответов (accuracy).
4. Обучите SVM по всей выборке с лучшим параметром C, найденным
на предыдущем шаге.
5. Найдите 10 слов с наибольшим по модулю весом. Они являются
ответом на это задание. Укажите их через запятую, в нижнем регистре, в лексикографическом порядке.
Отве'''



# 1
newsgroups = datasets.fetch_20newsgroups(subset='all', categories=['alt.atheism', 'sci.space'])
X = newsgroups.data
y = newsgroups.target







# 2
vectorizer = TfidfVectorizer()
vectorizer.fit_transform(X)




# 3
grid = {'C': np.power(10.0, np.arange(-5, 6))}
cv = KFold(y.size, shuffle=True, random_state=241)
model = SVC(kernel='linear', random_state=241)
gs = GridSearchCV(model, grid, scoring='accuracy', cv=cv)
gs.fit(vectorizer.transform(X), y)

C = gs.best_params_.get('C')



# 4
model = SVC(kernel='linear', random_state=241, C=C)
model.fit(vectorizer.transform(X), y)




# 5
words = vectorizer.get_feature_names()
coef = pandas.DataFrame(model.coef_.data, model.coef_.indices)
top_words = coef[0].map(lambda w: abs(w)).sort_values(ascending=False).head(10).index.map(lambda i: words[i])
top_words.sort()
print_answer(1, ','.join(top_words))
